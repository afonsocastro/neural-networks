{"layers": [{"id": 0, "neurons": 16, "activation": "selu"}, {"id": 1, "neurons": 32, "activation": "relu"}], "lr": 0.01, "n_layers": 2, "dropout": 0.2, "optimizer": "Adam", "loss": "sparse_categorical_crossentropy", "batch_size": 96, "epochs": 500, "early_stop_patience": 20}